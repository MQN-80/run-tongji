{"version":3,"sources":["index.js","mobilenet.js","base_model.js","multi_pose/decode_multiple_poses.js","multi_pose/build_part_with_score_queue.js","multi_pose/max_heap.js","multi_pose/decode_pose.js","keypoints.js","multi_pose/util.js","single_pose/decode_single_pose.js","single_pose/argmax2d.js","single_pose/util.js","posenet_model.js","checkpoints.js","resnet.js","util.js","version.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;AACA,ACHA;ADIA,ACHA;ADIA,ACHA;ACFA,AFMA,ACHA;ACFA,AFMA,ACHA;ACFA,AFMA,ACHA;ACFA,AFMA,ACHA,AENA;ADIA,AFMA,ACHA,AENA;ADIA,AFMA,ACHA,AENA;ADIA,AFMA,ACHA,AGTA,ADGA;ADIA,AFMA,ACHA,AGTA,ADGA;ADIA,AFMA,ACHA,AGTA,ADGA;ADIA,AFMA,ACHA,AGTA,ADGA,AENA;AHUA,AFMA,ACHA,AGTA,ADGA,AENA;AHUA,AFMA,ACHA,AGTA,ADGA,AENA;AHUA,AFMA,ACHA,AGTA,ADGA,AGTA,ADGA;AHUA,AFMA,ACHA,AGTA,ADGA,AGTA,ADGA;AHUA,AFMA,ACHA,AGTA,ADGA,AGTA,ADGA;AHUA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA;AHUA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA;AHUA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA;AHUA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA;ANmBA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA;ANmBA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA;ANmBA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,ACHA;APsBA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,ACHA;APsBA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,ACHA;APsBA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AENA,ADGA;APsBA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AENA,ADGA;APsBA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AENA,ADGA;APsBA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AENA,ADGA,AENA;AT4BA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AENA,ADGA,AENA;AT4BA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AENA,ADGA,AENA;AT4BA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AFMA,ADGA,AENA;AT4BA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AFMA,ADGA,AENA;AT4BA,AFMA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AFMA,ADGA,AENA;AT4BA,AWjCA,AbuCA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AFMA,ADGA,AENA;AT4BA,AWjCA,AbuCA,AOrBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AFMA,ADGA,AENA;AT4BA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AFMA,ADGA,AENA;AT4BA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA;AT4BA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA;AT4BA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA;AT4BA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA,ACHA;Ad2CA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA,ACHA;Ad2CA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA,ACHA;Ad2CA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA,ACHA;Ad2CA,AWjCA,ANkBA,ANkBA,AGTA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA,ACHA;Ad2CA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA,ACHA;Ad2CA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA,ACHA;Ad2CA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,AJYA,ADGA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AbwCA,AWjCA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AFOA,ANkBA,AHSA,ADGA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AFOA,ANkBA,AJYA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AFOA,ANkBA,AJYA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AFOA,ANkBA,AJYA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AFOA,ANkBA,AJYA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AFOA,ANkBA,AJYA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;AFOA,ANkBA,AJYA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;ARyBA,AJYA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;ARyBA,AJYA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;ARyBA,AJYA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;ARyBA,AJYA,AGTA,ADGA,AGTA,AIZA,AENA,ALeA,AENA,AIZA;ARyBA,AJYA,AGTA,ADGA,AOrBA,AHSA,AENA,AIZA;ARyBA,AJYA,AGTA,ADGA,AOrBA,AHSA,AMlBA;ARyBA,AJYA,AGTA,ADGA,AOrBA,AHSA,AMlBA;ARyBA,AJYA,AGTA,ADGA,AOrBA,AHSA,AMlBA;ARyBA,AJYA,AGTA,ADGA,AOrBA,AHSA,AMlBA;ARyBA,AJYA,AGTA,ADGA,AOrBA,AHSA,AMlBA;ARyBA,AJYA,AGTA,ADGA,AOrBA,AHSA,AMlBA;ARyBA,AJYA,AGTA,ADGA,AOrBA,AHSA,AMlBA;ARyBA,AJYA,AGTA,ADGA,AOrBA,AHSA,AMlBA;ARyBA,AJYA,AGTA,AMlBA,AHSA,AMlBA;ARyBA,AJYA,AGTA,AMlBA,AHSA,AMlBA;ARyBA,AJYA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AGTA,AMlBA,AHSA,AMlBA;AZqCA,AS3BA,AHSA,AMlBA;AZqCA,AS3BA,AHSA,AMlBA;AZqCA,AS3BA,AHSA,AMlBA;AZqCA,AS3BA,AHSA,AMlBA;AZqCA,AS3BA,AHSA,AMlBA;AZqCA,AS3BA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AHSA,AMlBA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar mobilenet_1 = require(\"./mobilenet\");\nexports.MobileNet = mobilenet_1.MobileNet;\nvar decode_multiple_poses_1 = require(\"./multi_pose/decode_multiple_poses\");\nexports.decodeMultiplePoses = decode_multiple_poses_1.decodeMultiplePoses;\nvar decode_single_pose_1 = require(\"./single_pose/decode_single_pose\");\nexports.decodeSinglePose = decode_single_pose_1.decodeSinglePose;\nvar keypoints_1 = require(\"./keypoints\");\nexports.partChannels = keypoints_1.partChannels;\nexports.partIds = keypoints_1.partIds;\nexports.partNames = keypoints_1.partNames;\nexports.poseChain = keypoints_1.poseChain;\nvar posenet_model_1 = require(\"./posenet_model\");\nexports.load = posenet_model_1.load;\nexports.PoseNet = posenet_model_1.PoseNet;\nvar util_1 = require(\"./util\");\nexports.getAdjacentKeyPoints = util_1.getAdjacentKeyPoints;\nexports.getBoundingBox = util_1.getBoundingBox;\nexports.getBoundingBoxPoints = util_1.getBoundingBoxPoints;\nexports.scaleAndFlipPoses = util_1.scaleAndFlipPoses;\nexports.scalePose = util_1.scalePose;\nvar version_1 = require(\"./version\");\nexports.version = version_1.version;\n//# sourceMappingURL=index.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar base_model_1 = require(\"./base_model\");\nvar MobileNet = /** @class */ (function (_super) {\n    __extends(MobileNet, _super);\n    function MobileNet() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    MobileNet.prototype.preprocessInput = function (input) {\n        // Normalize the pixels [0, 255] to be between [-1, 1].\n        return tf.tidy(function () { return tf.sub(tf.div(input, 127.5), 1.0); });\n    };\n    MobileNet.prototype.nameOutputResults = function (results) {\n        var offsets = results[0], heatmap = results[1], displacementFwd = results[2], displacementBwd = results[3];\n        return { offsets: offsets, heatmap: heatmap, displacementFwd: displacementFwd, displacementBwd: displacementBwd };\n    };\n    return MobileNet;\n}(base_model_1.BaseModel));\nexports.MobileNet = MobileNet;\n//# sourceMappingURL=mobilenet.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\n/**\n * PoseNet supports using various convolution neural network models\n * (e.g. ResNet and MobileNetV1) as its underlying base model.\n * The following BaseModel interface defines a unified interface for\n * creating such PoseNet base models. Currently both MobileNet (in\n * ./mobilenet.ts) and ResNet (in ./resnet.ts) implements the BaseModel\n * interface. New base models that conform to the BaseModel interface can be\n * added to PoseNet.\n */\nvar BaseModel = /** @class */ (function () {\n    function BaseModel(model, outputStride) {\n        this.model = model;\n        this.outputStride = outputStride;\n        var inputShape = this.model.inputs[0].shape;\n        tf.util.assert((inputShape[1] === -1) && (inputShape[2] === -1), function () { return \"Input shape [\" + inputShape[1] + \", \" + inputShape[2] + \"] \" +\n            \"must both be equal to or -1\"; });\n    }\n    /**\n     * Predicts intermediate Tensor representations.\n     *\n     * @param input The input RGB image of the base model.\n     * A Tensor of shape: [`inputResolution`, `inputResolution`, 3].\n     *\n     * @return A dictionary of base model's intermediate predictions.\n     * The returned dictionary should contains the following elements:\n     * heatmapScores: A Tensor3D that represents the heatmapScores.\n     * offsets: A Tensor3D that represents the offsets.\n     * displacementFwd: A Tensor3D that represents the forward displacement.\n     * displacementBwd: A Tensor3D that represents the backward displacement.\n     */\n    BaseModel.prototype.predict = function (input) {\n        var _this = this;\n        return tf.tidy(function () {\n            var asFloat = _this.preprocessInput(tf.cast(input, 'float32'));\n            var asBatch = tf.expandDims(asFloat, 0);\n            var results = _this.model.predict(asBatch);\n            var results3d = results.map(function (y) { return tf.squeeze(y, [0]); });\n            var namedResults = _this.nameOutputResults(results3d);\n            return {\n                heatmapScores: tf.sigmoid(namedResults.heatmap),\n                offsets: namedResults.offsets,\n                displacementFwd: namedResults.displacementFwd,\n                displacementBwd: namedResults.displacementBwd\n            };\n        });\n    };\n    /**\n     * Releases the CPU and GPU memory allocated by the model.\n     */\n    BaseModel.prototype.dispose = function () {\n        this.model.dispose();\n    };\n    return BaseModel;\n}());\nexports.BaseModel = BaseModel;\n//# sourceMappingURL=base_model.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar build_part_with_score_queue_1 = require(\"./build_part_with_score_queue\");\nvar decode_pose_1 = require(\"./decode_pose\");\nvar util_1 = require(\"./util\");\nfunction withinNmsRadiusOfCorrespondingPoint(poses, squaredNmsRadius, _a, keypointId) {\n    var x = _a.x, y = _a.y;\n    return poses.some(function (_a) {\n        var keypoints = _a.keypoints;\n        var correspondingKeypoint = keypoints[keypointId].position;\n        return util_1.squaredDistance(y, x, correspondingKeypoint.y, correspondingKeypoint.x) <=\n            squaredNmsRadius;\n    });\n}\n/* Score the newly proposed object instance without taking into account\n * the scores of the parts that overlap with any previously detected\n * instance.\n */\nfunction getInstanceScore(existingPoses, squaredNmsRadius, instanceKeypoints) {\n    var notOverlappedKeypointScores = instanceKeypoints.reduce(function (result, _a, keypointId) {\n        var position = _a.position, score = _a.score;\n        if (!withinNmsRadiusOfCorrespondingPoint(existingPoses, squaredNmsRadius, position, keypointId)) {\n            result += score;\n        }\n        return result;\n    }, 0.0);\n    return notOverlappedKeypointScores /= instanceKeypoints.length;\n}\n// A point (y, x) is considered as root part candidate if its score is a\n// maximum in a window |y - y'| <= kLocalMaximumRadius, |x - x'| <=\n// kLocalMaximumRadius.\nvar kLocalMaximumRadius = 1;\n/**\n * Detects multiple poses and finds their parts from part scores and\n * displacement vectors. It returns up to `maxDetections` object instance\n * detections in decreasing root score order. It works as follows: We first\n * create a priority queue with local part score maxima above\n * `scoreThreshold`, considering all parts at the same time. Then we\n * iteratively pull the top  element of the queue (in decreasing score order)\n * and treat it as a root candidate for a new object instance. To avoid\n * duplicate detections, we reject the root candidate if it is within a disk\n * of `nmsRadius` pixels from the corresponding part of a previously detected\n * instance, which is a form of part-based non-maximum suppression (NMS). If\n * the root candidate passes the NMS check, we start a new object instance\n * detection, treating the corresponding part as root and finding the\n * positions of the remaining parts by following the displacement vectors\n * along the tree-structured part graph. We assign to the newly detected\n * instance a score equal to the sum of scores of its parts which have not\n * been claimed by a previous instance (i.e., those at least `nmsRadius`\n * pixels away from the corresponding part of all previously detected\n * instances), divided by the total number of parts `numParts`.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param displacementsFwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the forward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param displacementsBwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the backward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @param maxPoseDetections Maximum number of returned instance detections per\n * image.\n *\n * @param scoreThreshold Only return instance detections that have root part\n * score greater or equal to this value. Defaults to 0.5.\n *\n * @param nmsRadius Non-maximum suppression part distance. It needs to be\n * strictly positive. Two parts suppress each other if they are less than\n * `nmsRadius` pixels away. Defaults to 20.\n *\n * @return An array of poses and their scores, each containing keypoints and\n * the corresponding keypoint scores.\n */\nfunction decodeMultiplePoses(scoresBuffer, offsetsBuffer, displacementsFwdBuffer, displacementsBwdBuffer, outputStride, maxPoseDetections, scoreThreshold, nmsRadius) {\n    if (scoreThreshold === void 0) { scoreThreshold = 0.5; }\n    if (nmsRadius === void 0) { nmsRadius = 20; }\n    var poses = [];\n    var queue = build_part_with_score_queue_1.buildPartWithScoreQueue(scoreThreshold, kLocalMaximumRadius, scoresBuffer);\n    var squaredNmsRadius = nmsRadius * nmsRadius;\n    // Generate at most maxDetections object instances per image in\n    // decreasing root part score order.\n    while (poses.length < maxPoseDetections && !queue.empty()) {\n        // The top element in the queue is the next root candidate.\n        var root = queue.dequeue();\n        // Part-based non-maximum suppression: We reject a root candidate if it\n        // is within a disk of `nmsRadius` pixels from the corresponding part of\n        // a previously detected instance.\n        var rootImageCoords = util_1.getImageCoords(root.part, outputStride, offsetsBuffer);\n        if (withinNmsRadiusOfCorrespondingPoint(poses, squaredNmsRadius, rootImageCoords, root.part.id)) {\n            continue;\n        }\n        // Start a new detection instance at the position of the root.\n        var keypoints = decode_pose_1.decodePose(root, scoresBuffer, offsetsBuffer, outputStride, displacementsFwdBuffer, displacementsBwdBuffer);\n        var score = getInstanceScore(poses, squaredNmsRadius, keypoints);\n        poses.push({ keypoints: keypoints, score: score });\n    }\n    return poses;\n}\nexports.decodeMultiplePoses = decodeMultiplePoses;\n//# sourceMappingURL=decode_multiple_poses.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar max_heap_1 = require(\"./max_heap\");\nfunction scoreIsMaximumInLocalWindow(keypointId, score, heatmapY, heatmapX, localMaximumRadius, scores) {\n    var _a = scores.shape, height = _a[0], width = _a[1];\n    var localMaximum = true;\n    var yStart = Math.max(heatmapY - localMaximumRadius, 0);\n    var yEnd = Math.min(heatmapY + localMaximumRadius + 1, height);\n    for (var yCurrent = yStart; yCurrent < yEnd; ++yCurrent) {\n        var xStart = Math.max(heatmapX - localMaximumRadius, 0);\n        var xEnd = Math.min(heatmapX + localMaximumRadius + 1, width);\n        for (var xCurrent = xStart; xCurrent < xEnd; ++xCurrent) {\n            if (scores.get(yCurrent, xCurrent, keypointId) > score) {\n                localMaximum = false;\n                break;\n            }\n        }\n        if (!localMaximum) {\n            break;\n        }\n    }\n    return localMaximum;\n}\n/**\n * Builds a priority queue with part candidate positions for a specific image in\n * the batch. For this we find all local maxima in the score maps with score\n * values above a threshold. We create a single priority queue across all parts.\n */\nfunction buildPartWithScoreQueue(scoreThreshold, localMaximumRadius, scores) {\n    var _a = scores.shape, height = _a[0], width = _a[1], numKeypoints = _a[2];\n    var queue = new max_heap_1.MaxHeap(height * width * numKeypoints, function (_a) {\n        var score = _a.score;\n        return score;\n    });\n    for (var heatmapY = 0; heatmapY < height; ++heatmapY) {\n        for (var heatmapX = 0; heatmapX < width; ++heatmapX) {\n            for (var keypointId = 0; keypointId < numKeypoints; ++keypointId) {\n                var score = scores.get(heatmapY, heatmapX, keypointId);\n                // Only consider parts with score greater or equal to threshold as\n                // root candidates.\n                if (score < scoreThreshold) {\n                    continue;\n                }\n                // Only consider keypoints whose score is maximum in a local window.\n                if (scoreIsMaximumInLocalWindow(keypointId, score, heatmapY, heatmapX, localMaximumRadius, scores)) {\n                    queue.enqueue({ score: score, part: { heatmapY: heatmapY, heatmapX: heatmapX, id: keypointId } });\n                }\n            }\n        }\n    }\n    return queue;\n}\nexports.buildPartWithScoreQueue = buildPartWithScoreQueue;\n//# sourceMappingURL=build_part_with_score_queue.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// algorithm based on Coursera Lecture from Algorithms, Part 1:\n// https://www.coursera.org/learn/algorithms-part1/lecture/ZjoSM/heapsort\nfunction half(k) {\n    return Math.floor(k / 2);\n}\nvar MaxHeap = /** @class */ (function () {\n    function MaxHeap(maxSize, getElementValue) {\n        this.priorityQueue = new Array(maxSize);\n        this.numberOfElements = -1;\n        this.getElementValue = getElementValue;\n    }\n    MaxHeap.prototype.enqueue = function (x) {\n        this.priorityQueue[++this.numberOfElements] = x;\n        this.swim(this.numberOfElements);\n    };\n    MaxHeap.prototype.dequeue = function () {\n        var max = this.priorityQueue[0];\n        this.exchange(0, this.numberOfElements--);\n        this.sink(0);\n        this.priorityQueue[this.numberOfElements + 1] = null;\n        return max;\n    };\n    MaxHeap.prototype.empty = function () {\n        return this.numberOfElements === -1;\n    };\n    MaxHeap.prototype.size = function () {\n        return this.numberOfElements + 1;\n    };\n    MaxHeap.prototype.all = function () {\n        return this.priorityQueue.slice(0, this.numberOfElements + 1);\n    };\n    MaxHeap.prototype.max = function () {\n        return this.priorityQueue[0];\n    };\n    MaxHeap.prototype.swim = function (k) {\n        while (k > 0 && this.less(half(k), k)) {\n            this.exchange(k, half(k));\n            k = half(k);\n        }\n    };\n    MaxHeap.prototype.sink = function (k) {\n        while (2 * k <= this.numberOfElements) {\n            var j = 2 * k;\n            if (j < this.numberOfElements && this.less(j, j + 1)) {\n                j++;\n            }\n            if (!this.less(k, j)) {\n                break;\n            }\n            this.exchange(k, j);\n            k = j;\n        }\n    };\n    MaxHeap.prototype.getValueAt = function (i) {\n        return this.getElementValue(this.priorityQueue[i]);\n    };\n    MaxHeap.prototype.less = function (i, j) {\n        return this.getValueAt(i) < this.getValueAt(j);\n    };\n    MaxHeap.prototype.exchange = function (i, j) {\n        var t = this.priorityQueue[i];\n        this.priorityQueue[i] = this.priorityQueue[j];\n        this.priorityQueue[j] = t;\n    };\n    return MaxHeap;\n}());\nexports.MaxHeap = MaxHeap;\n//# sourceMappingURL=max_heap.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar keypoints_1 = require(\"../keypoints\");\nvar util_1 = require(\"./util\");\nvar util_2 = require(\"./util\");\nvar parentChildrenTuples = keypoints_1.poseChain.map(function (_a) {\n    var parentJoinName = _a[0], childJoinName = _a[1];\n    return ([keypoints_1.partIds[parentJoinName], keypoints_1.partIds[childJoinName]]);\n});\nvar parentToChildEdges = parentChildrenTuples.map(function (_a) {\n    var childJointId = _a[1];\n    return childJointId;\n});\nvar childToParentEdges = parentChildrenTuples.map(function (_a) {\n    var parentJointId = _a[0];\n    return parentJointId;\n});\nfunction getDisplacement(edgeId, point, displacements) {\n    var numEdges = displacements.shape[2] / 2;\n    return {\n        y: displacements.get(point.y, point.x, edgeId),\n        x: displacements.get(point.y, point.x, numEdges + edgeId)\n    };\n}\nfunction getStridedIndexNearPoint(point, outputStride, height, width) {\n    return {\n        y: util_1.clamp(Math.round(point.y / outputStride), 0, height - 1),\n        x: util_1.clamp(Math.round(point.x / outputStride), 0, width - 1)\n    };\n}\n/**\n * We get a new keypoint along the `edgeId` for the pose instance, assuming\n * that the position of the `idSource` part is already known. For this, we\n * follow the displacement vector from the source to target part (stored in\n * the `i`-t channel of the displacement tensor). The displaced keypoint\n * vector is refined using the offset vector by `offsetRefineStep` times.\n */\nfunction traverseToTargetKeypoint(edgeId, sourceKeypoint, targetKeypointId, scoresBuffer, offsets, outputStride, displacements, offsetRefineStep) {\n    if (offsetRefineStep === void 0) { offsetRefineStep = 2; }\n    var _a = scoresBuffer.shape, height = _a[0], width = _a[1];\n    // Nearest neighbor interpolation for the source->target displacements.\n    var sourceKeypointIndices = getStridedIndexNearPoint(sourceKeypoint.position, outputStride, height, width);\n    var displacement = getDisplacement(edgeId, sourceKeypointIndices, displacements);\n    var displacedPoint = util_2.addVectors(sourceKeypoint.position, displacement);\n    var targetKeypoint = displacedPoint;\n    for (var i = 0; i < offsetRefineStep; i++) {\n        var targetKeypointIndices = getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n        var offsetPoint = util_1.getOffsetPoint(targetKeypointIndices.y, targetKeypointIndices.x, targetKeypointId, offsets);\n        targetKeypoint = util_2.addVectors({\n            x: targetKeypointIndices.x * outputStride,\n            y: targetKeypointIndices.y * outputStride\n        }, { x: offsetPoint.x, y: offsetPoint.y });\n    }\n    var targetKeyPointIndices = getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n    var score = scoresBuffer.get(targetKeyPointIndices.y, targetKeyPointIndices.x, targetKeypointId);\n    return { position: targetKeypoint, part: keypoints_1.partNames[targetKeypointId], score: score };\n}\n/**\n * Follows the displacement fields to decode the full pose of the object\n * instance given the position of a part that acts as root.\n *\n * @return An array of decoded keypoints and their scores for a single pose\n */\nfunction decodePose(root, scores, offsets, outputStride, displacementsFwd, displacementsBwd) {\n    var numParts = scores.shape[2];\n    var numEdges = parentToChildEdges.length;\n    var instanceKeypoints = new Array(numParts);\n    // Start a new detection instance at the position of the root.\n    var rootPart = root.part, rootScore = root.score;\n    var rootPoint = util_2.getImageCoords(rootPart, outputStride, offsets);\n    instanceKeypoints[rootPart.id] = {\n        score: rootScore,\n        part: keypoints_1.partNames[rootPart.id],\n        position: rootPoint\n    };\n    // Decode the part positions upwards in the tree, following the backward\n    // displacements.\n    for (var edge = numEdges - 1; edge >= 0; --edge) {\n        var sourceKeypointId = parentToChildEdges[edge];\n        var targetKeypointId = childToParentEdges[edge];\n        if (instanceKeypoints[sourceKeypointId] &&\n            !instanceKeypoints[targetKeypointId]) {\n            instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores, offsets, outputStride, displacementsBwd);\n        }\n    }\n    // Decode the part positions downwards in the tree, following the forward\n    // displacements.\n    for (var edge = 0; edge < numEdges; ++edge) {\n        var sourceKeypointId = childToParentEdges[edge];\n        var targetKeypointId = parentToChildEdges[edge];\n        if (instanceKeypoints[sourceKeypointId] &&\n            !instanceKeypoints[targetKeypointId]) {\n            instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores, offsets, outputStride, displacementsFwd);\n        }\n    }\n    return instanceKeypoints;\n}\nexports.decodePose = decodePose;\n//# sourceMappingURL=decode_pose.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.partNames = [\n    'nose', 'leftEye', 'rightEye', 'leftEar', 'rightEar', 'leftShoulder',\n    'rightShoulder', 'leftElbow', 'rightElbow', 'leftWrist', 'rightWrist',\n    'leftHip', 'rightHip', 'leftKnee', 'rightKnee', 'leftAnkle', 'rightAnkle'\n];\nexports.NUM_KEYPOINTS = exports.partNames.length;\nexports.partIds = exports.partNames.reduce(function (result, jointName, i) {\n    result[jointName] = i;\n    return result;\n}, {});\nvar connectedPartNames = [\n    ['leftHip', 'leftShoulder'], ['leftElbow', 'leftShoulder'],\n    ['leftElbow', 'leftWrist'], ['leftHip', 'leftKnee'],\n    ['leftKnee', 'leftAnkle'], ['rightHip', 'rightShoulder'],\n    ['rightElbow', 'rightShoulder'], ['rightElbow', 'rightWrist'],\n    ['rightHip', 'rightKnee'], ['rightKnee', 'rightAnkle'],\n    ['leftShoulder', 'rightShoulder'], ['leftHip', 'rightHip']\n];\n/*\n * Define the skeleton. This defines the parent->child relationships of our\n * tree. Arbitrarily this defines the nose as the root of the tree, however\n * since we will infer the displacement for both parent->child and\n * child->parent, we can define the tree root as any node.\n */\nexports.poseChain = [\n    ['nose', 'leftEye'], ['leftEye', 'leftEar'], ['nose', 'rightEye'],\n    ['rightEye', 'rightEar'], ['nose', 'leftShoulder'],\n    ['leftShoulder', 'leftElbow'], ['leftElbow', 'leftWrist'],\n    ['leftShoulder', 'leftHip'], ['leftHip', 'leftKnee'],\n    ['leftKnee', 'leftAnkle'], ['nose', 'rightShoulder'],\n    ['rightShoulder', 'rightElbow'], ['rightElbow', 'rightWrist'],\n    ['rightShoulder', 'rightHip'], ['rightHip', 'rightKnee'],\n    ['rightKnee', 'rightAnkle']\n];\nexports.connectedPartIndices = connectedPartNames.map(function (_a) {\n    var jointNameA = _a[0], jointNameB = _a[1];\n    return ([exports.partIds[jointNameA], exports.partIds[jointNameB]]);\n});\nexports.partChannels = [\n    'left_face',\n    'right_face',\n    'right_upper_leg_front',\n    'right_lower_leg_back',\n    'right_upper_leg_back',\n    'left_lower_leg_front',\n    'left_upper_leg_front',\n    'left_upper_leg_back',\n    'left_lower_leg_back',\n    'right_feet',\n    'right_lower_leg_front',\n    'left_feet',\n    'torso_front',\n    'torso_back',\n    'right_upper_arm_front',\n    'right_upper_arm_back',\n    'right_lower_arm_back',\n    'left_lower_arm_front',\n    'left_upper_arm_front',\n    'left_upper_arm_back',\n    'left_lower_arm_back',\n    'right_hand',\n    'right_lower_arm_front',\n    'left_hand'\n];\n//# sourceMappingURL=keypoints.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar keypoints_1 = require(\"../keypoints\");\nfunction getOffsetPoint(y, x, keypoint, offsets) {\n    return {\n        y: offsets.get(y, x, keypoint),\n        x: offsets.get(y, x, keypoint + keypoints_1.NUM_KEYPOINTS)\n    };\n}\nexports.getOffsetPoint = getOffsetPoint;\nfunction getImageCoords(part, outputStride, offsets) {\n    var heatmapY = part.heatmapY, heatmapX = part.heatmapX, keypoint = part.id;\n    var _a = getOffsetPoint(heatmapY, heatmapX, keypoint, offsets), y = _a.y, x = _a.x;\n    return {\n        x: part.heatmapX * outputStride + x,\n        y: part.heatmapY * outputStride + y\n    };\n}\nexports.getImageCoords = getImageCoords;\nfunction fillArray(element, size) {\n    var result = new Array(size);\n    for (var i = 0; i < size; i++) {\n        result[i] = element;\n    }\n    return result;\n}\nexports.fillArray = fillArray;\nfunction clamp(a, min, max) {\n    if (a < min) {\n        return min;\n    }\n    if (a > max) {\n        return max;\n    }\n    return a;\n}\nexports.clamp = clamp;\nfunction squaredDistance(y1, x1, y2, x2) {\n    var dy = y2 - y1;\n    var dx = x2 - x1;\n    return dy * dy + dx * dx;\n}\nexports.squaredDistance = squaredDistance;\nfunction addVectors(a, b) {\n    return { x: a.x + b.x, y: a.y + b.y };\n}\nexports.addVectors = addVectors;\nfunction clampVector(a, min, max) {\n    return { y: clamp(a.y, min, max), x: clamp(a.x, min, max) };\n}\nexports.clampVector = clampVector;\n//# sourceMappingURL=util.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar keypoints_1 = require(\"../keypoints\");\nvar argmax2d_1 = require(\"./argmax2d\");\nvar util_1 = require(\"./util\");\n/**\n * Detects a single pose and finds its parts from part scores and offset\n * vectors. It returns a single pose detection. It works as follows:\n * argmax2d is done on the scores to get the y and x index in the heatmap\n * with the highest score for each part, which is essentially where the\n * part is most likely to exist. This produces a tensor of size 17x2, with\n * each row being the y and x index in the heatmap for each keypoint.\n * The offset vector for each for each part is retrieved by getting the\n * y and x from the offsets corresponding to the y and x index in the\n * heatmap for that part. This produces a tensor of size 17x2, with each\n * row being the offset vector for the corresponding keypoint.\n * To get the keypoint, each partâ€™s heatmap y and x are multiplied\n * by the output stride then added to their corresponding offset vector,\n * which is in the same scale as the original image.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @return A promise that resolves with single pose with a confidence score,\n * which contains an array of keypoints indexed by part id, each with a score\n * and position.\n */\nfunction decodeSinglePose(heatmapScores, offsets, outputStride) {\n    return __awaiter(this, void 0, void 0, function () {\n        var totalScore, heatmapValues, allTensorBuffers, scoresBuffer, offsetsBuffer, heatmapValuesBuffer, offsetPoints, offsetPointsBuffer, keypointConfidence, keypoints;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    totalScore = 0.0;\n                    heatmapValues = argmax2d_1.argmax2d(heatmapScores);\n                    return [4 /*yield*/, Promise.all([heatmapScores.buffer(), offsets.buffer(), heatmapValues.buffer()])];\n                case 1:\n                    allTensorBuffers = _a.sent();\n                    scoresBuffer = allTensorBuffers[0];\n                    offsetsBuffer = allTensorBuffers[1];\n                    heatmapValuesBuffer = allTensorBuffers[2];\n                    offsetPoints = util_1.getOffsetPoints(heatmapValuesBuffer, outputStride, offsetsBuffer);\n                    return [4 /*yield*/, offsetPoints.buffer()];\n                case 2:\n                    offsetPointsBuffer = _a.sent();\n                    keypointConfidence = Array.from(util_1.getPointsConfidence(scoresBuffer, heatmapValuesBuffer));\n                    keypoints = keypointConfidence.map(function (score, keypointId) {\n                        totalScore += score;\n                        return {\n                            position: {\n                                y: offsetPointsBuffer.get(keypointId, 0),\n                                x: offsetPointsBuffer.get(keypointId, 1)\n                            },\n                            part: keypoints_1.partNames[keypointId],\n                            score: score\n                        };\n                    });\n                    heatmapValues.dispose();\n                    offsetPoints.dispose();\n                    return [2 /*return*/, { keypoints: keypoints, score: totalScore / keypoints.length }];\n            }\n        });\n    });\n}\nexports.decodeSinglePose = decodeSinglePose;\n//# sourceMappingURL=decode_single_pose.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\nfunction mod(a, b) {\n    return tf.tidy(function () {\n        var floored = tf.div(a, tf.scalar(b, 'int32'));\n        return tf.sub(a, tf.mul(floored, tf.scalar(b, 'int32')));\n    });\n}\nfunction argmax2d(inputs) {\n    var _a = inputs.shape, height = _a[0], width = _a[1], depth = _a[2];\n    return tf.tidy(function () {\n        var reshaped = tf.reshape(inputs, [height * width, depth]);\n        var coords = tf.argMax(reshaped, 0);\n        var yCoords = tf.expandDims(tf.div(coords, tf.scalar(width, 'int32')), 1);\n        var xCoords = tf.expandDims(mod(coords, width), 1);\n        return tf.concat([yCoords, xCoords], 1);\n    });\n}\nexports.argmax2d = argmax2d;\n//# sourceMappingURL=argmax2d.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar keypoints_1 = require(\"../keypoints\");\nfunction getPointsConfidence(heatmapScores, heatMapCoords) {\n    var numKeypoints = heatMapCoords.shape[0];\n    var result = new Float32Array(numKeypoints);\n    for (var keypoint = 0; keypoint < numKeypoints; keypoint++) {\n        var y = heatMapCoords.get(keypoint, 0);\n        var x = heatMapCoords.get(keypoint, 1);\n        result[keypoint] = heatmapScores.get(y, x, keypoint);\n    }\n    return result;\n}\nexports.getPointsConfidence = getPointsConfidence;\nfunction getOffsetPoint(y, x, keypoint, offsetsBuffer) {\n    return {\n        y: offsetsBuffer.get(y, x, keypoint),\n        x: offsetsBuffer.get(y, x, keypoint + keypoints_1.NUM_KEYPOINTS)\n    };\n}\nfunction getOffsetVectors(heatMapCoordsBuffer, offsetsBuffer) {\n    var result = [];\n    for (var keypoint = 0; keypoint < keypoints_1.NUM_KEYPOINTS; keypoint++) {\n        var heatmapY = heatMapCoordsBuffer.get(keypoint, 0).valueOf();\n        var heatmapX = heatMapCoordsBuffer.get(keypoint, 1).valueOf();\n        var _a = getOffsetPoint(heatmapY, heatmapX, keypoint, offsetsBuffer), x = _a.x, y = _a.y;\n        result.push(y);\n        result.push(x);\n    }\n    return tf.tensor2d(result, [keypoints_1.NUM_KEYPOINTS, 2]);\n}\nexports.getOffsetVectors = getOffsetVectors;\nfunction getOffsetPoints(heatMapCoordsBuffer, outputStride, offsetsBuffer) {\n    return tf.tidy(function () {\n        var offsetVectors = getOffsetVectors(heatMapCoordsBuffer, offsetsBuffer);\n        return tf\n            .add(tf\n            .cast(tf\n            .mul(heatMapCoordsBuffer.toTensor(), tf.scalar(outputStride, 'int32')), 'float32'), offsetVectors);\n    });\n}\nexports.getOffsetPoints = getOffsetPoints;\n//# sourceMappingURL=util.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __assign = (this && this.__assign) || function () {\n    __assign = Object.assign || function(t) {\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\n            s = arguments[i];\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))\n                t[p] = s[p];\n        }\n        return t;\n    };\n    return __assign.apply(this, arguments);\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfconv = require(\"@tensorflow/tfjs-converter\");\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar checkpoints_1 = require(\"./checkpoints\");\nvar mobilenet_1 = require(\"./mobilenet\");\nvar decode_multiple_poses_1 = require(\"./multi_pose/decode_multiple_poses\");\nvar resnet_1 = require(\"./resnet\");\nvar decode_single_pose_1 = require(\"./single_pose/decode_single_pose\");\nvar util_1 = require(\"./util\");\n// The default configuration for loading MobileNetV1 based PoseNet.\n//\n// (And for references, the default configuration for loading ResNet\n// based PoseNet is also included).\n//\n// ```\n// const RESNET_CONFIG = {\n//   architecture: 'ResNet50',\n//   outputStride: 32,\n//   quantBytes: 2,\n// } as ModelConfig;\n// ```\nvar MOBILENET_V1_CONFIG = {\n    architecture: 'MobileNetV1',\n    outputStride: 16,\n    multiplier: 0.75,\n    inputResolution: 257,\n};\nvar VALID_ARCHITECTURE = ['MobileNetV1', 'ResNet50'];\nvar VALID_STRIDE = {\n    'MobileNetV1': [8, 16, 32],\n    'ResNet50': [32, 16]\n};\nvar VALID_MULTIPLIER = {\n    'MobileNetV1': [0.50, 0.75, 1.0],\n    'ResNet50': [1.0]\n};\nvar VALID_QUANT_BYTES = [1, 2, 4];\nfunction validateModelConfig(config) {\n    config = config || MOBILENET_V1_CONFIG;\n    if (config.architecture == null) {\n        config.architecture = 'MobileNetV1';\n    }\n    if (VALID_ARCHITECTURE.indexOf(config.architecture) < 0) {\n        throw new Error(\"Invalid architecture \" + config.architecture + \". \" +\n            (\"Should be one of \" + VALID_ARCHITECTURE));\n    }\n    if (config.inputResolution == null) {\n        config.inputResolution = 257;\n    }\n    util_1.validateInputResolution(config.inputResolution);\n    if (config.outputStride == null) {\n        config.outputStride = 16;\n    }\n    if (VALID_STRIDE[config.architecture].indexOf(config.outputStride) < 0) {\n        throw new Error(\"Invalid outputStride \" + config.outputStride + \". \" +\n            (\"Should be one of \" + VALID_STRIDE[config.architecture] + \" \") +\n            (\"for architecture \" + config.architecture + \".\"));\n    }\n    if (config.multiplier == null) {\n        config.multiplier = 1.0;\n    }\n    if (VALID_MULTIPLIER[config.architecture].indexOf(config.multiplier) < 0) {\n        throw new Error(\"Invalid multiplier \" + config.multiplier + \". \" +\n            (\"Should be one of \" + VALID_MULTIPLIER[config.architecture] + \" \") +\n            (\"for architecture \" + config.architecture + \".\"));\n    }\n    if (config.quantBytes == null) {\n        config.quantBytes = 4;\n    }\n    if (VALID_QUANT_BYTES.indexOf(config.quantBytes) < 0) {\n        throw new Error(\"Invalid quantBytes \" + config.quantBytes + \". \" +\n            (\"Should be one of \" + VALID_QUANT_BYTES + \" \") +\n            (\"for architecture \" + config.architecture + \".\"));\n    }\n    if (config.architecture === 'MobileNetV1' && config.outputStride === 32 &&\n        config.multiplier !== 1) {\n        throw new Error(\"When using an output stride of 32, \" +\n            \"you must select 1 as the multiplier.\");\n    }\n    return config;\n}\nexports.SINGLE_PERSON_INFERENCE_CONFIG = {\n    flipHorizontal: false\n};\nexports.MULTI_PERSON_INFERENCE_CONFIG = {\n    flipHorizontal: false,\n    maxDetections: 5,\n    scoreThreshold: 0.5,\n    nmsRadius: 20\n};\nfunction validateSinglePersonInferenceConfig(config) { }\nfunction validateMultiPersonInputConfig(config) {\n    var maxDetections = config.maxDetections, scoreThreshold = config.scoreThreshold, nmsRadius = config.nmsRadius;\n    if (maxDetections <= 0) {\n        throw new Error(\"Invalid maxDetections \" + maxDetections + \". \" +\n            \"Should be > 0\");\n    }\n    if (scoreThreshold < 0.0 || scoreThreshold > 1.0) {\n        throw new Error(\"Invalid scoreThreshold \" + scoreThreshold + \". \" +\n            \"Should be in range [0.0, 1.0]\");\n    }\n    if (nmsRadius <= 0) {\n        throw new Error(\"Invalid nmsRadius \" + nmsRadius + \".\");\n    }\n}\nvar PoseNet = /** @class */ (function () {\n    function PoseNet(net, inputResolution) {\n        util_1.assertValidOutputStride(net.outputStride);\n        util_1.assertValidResolution(inputResolution, net.outputStride);\n        this.baseModel = net;\n        this.inputResolution = inputResolution;\n    }\n    /**\n     * Infer through PoseNet, and estimates multiple poses using the outputs.\n     * This does standard ImageNet pre-processing before inferring through the\n     * model. The image should pixels should have values [0-255]. It detects\n     * multiple poses and finds their parts from part scores and displacement\n     * vectors using a fast greedy decoding algorithm.  It returns up to\n     * `config.maxDetections` object instance detections in decreasing root\n     * score order.\n     *\n     * @param input\n     * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n     * image to feed through the network.\n     *\n     * @param config MultiPoseEstimationConfig object that contains parameters\n     * for the PoseNet inference using multiple pose estimation.\n     *\n     * @return An array of poses and their scores, each containing keypoints and\n     * the corresponding keypoint scores.  The positions of the keypoints are\n     * in the same scale as the original image\n     */\n    PoseNet.prototype.estimateMultiplePoses = function (input, config) {\n        if (config === void 0) { config = exports.MULTI_PERSON_INFERENCE_CONFIG; }\n        return __awaiter(this, void 0, void 0, function () {\n            var configWithDefaults, outputStride, inputResolution, _a, height, width, _b, resized, padding, _c, heatmapScores, offsets, displacementFwd, displacementBwd, allTensorBuffers, scoresBuffer, offsetsBuffer, displacementsFwdBuffer, displacementsBwdBuffer, poses, resultPoses;\n            return __generator(this, function (_d) {\n                switch (_d.label) {\n                    case 0:\n                        configWithDefaults = __assign({}, exports.MULTI_PERSON_INFERENCE_CONFIG, config);\n                        validateMultiPersonInputConfig(config);\n                        outputStride = this.baseModel.outputStride;\n                        inputResolution = this.inputResolution;\n                        _a = util_1.getInputTensorDimensions(input), height = _a[0], width = _a[1];\n                        _b = util_1.padAndResizeTo(input, inputResolution), resized = _b.resized, padding = _b.padding;\n                        _c = this.baseModel.predict(resized), heatmapScores = _c.heatmapScores, offsets = _c.offsets, displacementFwd = _c.displacementFwd, displacementBwd = _c.displacementBwd;\n                        return [4 /*yield*/, util_1.toTensorBuffers3D([heatmapScores, offsets, displacementFwd, displacementBwd])];\n                    case 1:\n                        allTensorBuffers = _d.sent();\n                        scoresBuffer = allTensorBuffers[0];\n                        offsetsBuffer = allTensorBuffers[1];\n                        displacementsFwdBuffer = allTensorBuffers[2];\n                        displacementsBwdBuffer = allTensorBuffers[3];\n                        return [4 /*yield*/, decode_multiple_poses_1.decodeMultiplePoses(scoresBuffer, offsetsBuffer, displacementsFwdBuffer, displacementsBwdBuffer, outputStride, configWithDefaults.maxDetections, configWithDefaults.scoreThreshold, configWithDefaults.nmsRadius)];\n                    case 2:\n                        poses = _d.sent();\n                        resultPoses = util_1.scaleAndFlipPoses(poses, [height, width], inputResolution, padding, configWithDefaults.flipHorizontal);\n                        heatmapScores.dispose();\n                        offsets.dispose();\n                        displacementFwd.dispose();\n                        displacementBwd.dispose();\n                        resized.dispose();\n                        return [2 /*return*/, resultPoses];\n                }\n            });\n        });\n    };\n    /**\n     * Infer through PoseNet, and estimates a single pose using the outputs.\n     * This does standard ImageNet pre-processing before inferring through the\n     * model. The image should pixels should have values [0-255]. It detects\n     * multiple poses and finds their parts from part scores and displacement\n     * vectors using a fast greedy decoding algorithm.  It returns a single pose\n     *\n     * @param input\n     * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n     * image to feed through the network.\n     *\n     * @param config SinglePersonEstimationConfig object that contains\n     * parameters for the PoseNet inference using single pose estimation.\n     *\n     * @return An pose and its scores, containing keypoints and\n     * the corresponding keypoint scores.  The positions of the keypoints are\n     * in the same scale as the original image\n     */\n    PoseNet.prototype.estimateSinglePose = function (input, config) {\n        if (config === void 0) { config = exports.SINGLE_PERSON_INFERENCE_CONFIG; }\n        return __awaiter(this, void 0, void 0, function () {\n            var configWithDefaults, outputStride, inputResolution, _a, height, width, _b, resized, padding, _c, heatmapScores, offsets, displacementFwd, displacementBwd, pose, poses, resultPoses;\n            return __generator(this, function (_d) {\n                switch (_d.label) {\n                    case 0:\n                        configWithDefaults = __assign({}, exports.SINGLE_PERSON_INFERENCE_CONFIG, config);\n                        validateSinglePersonInferenceConfig(configWithDefaults);\n                        outputStride = this.baseModel.outputStride;\n                        inputResolution = this.inputResolution;\n                        _a = util_1.getInputTensorDimensions(input), height = _a[0], width = _a[1];\n                        _b = util_1.padAndResizeTo(input, inputResolution), resized = _b.resized, padding = _b.padding;\n                        _c = this.baseModel.predict(resized), heatmapScores = _c.heatmapScores, offsets = _c.offsets, displacementFwd = _c.displacementFwd, displacementBwd = _c.displacementBwd;\n                        return [4 /*yield*/, decode_single_pose_1.decodeSinglePose(heatmapScores, offsets, outputStride)];\n                    case 1:\n                        pose = _d.sent();\n                        poses = [pose];\n                        resultPoses = util_1.scaleAndFlipPoses(poses, [height, width], inputResolution, padding, configWithDefaults.flipHorizontal);\n                        heatmapScores.dispose();\n                        offsets.dispose();\n                        displacementFwd.dispose();\n                        displacementBwd.dispose();\n                        resized.dispose();\n                        return [2 /*return*/, resultPoses[0]];\n                }\n            });\n        });\n    };\n    /** Deprecated: Use either estimateSinglePose or estimateMultiplePoses */\n    PoseNet.prototype.estimatePoses = function (input, config) {\n        return __awaiter(this, void 0, void 0, function () {\n            var pose;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (!(config.decodingMethod === 'single-person')) return [3 /*break*/, 2];\n                        return [4 /*yield*/, this.estimateSinglePose(input, config)];\n                    case 1:\n                        pose = _a.sent();\n                        return [2 /*return*/, [pose]];\n                    case 2: return [2 /*return*/, this.estimateMultiplePoses(input, config)];\n                }\n            });\n        });\n    };\n    PoseNet.prototype.dispose = function () {\n        this.baseModel.dispose();\n    };\n    return PoseNet;\n}());\nexports.PoseNet = PoseNet;\nfunction loadMobileNet(config) {\n    return __awaiter(this, void 0, void 0, function () {\n        var outputStride, quantBytes, multiplier, url, graphModel, mobilenet, validInputResolution;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    outputStride = config.outputStride;\n                    quantBytes = config.quantBytes;\n                    multiplier = config.multiplier;\n                    if (tf == null) {\n                        throw new Error(\"Cannot find TensorFlow.js. If you are using a <script> tag, please \" +\n                            \"also include @tensorflow/tfjs on the page before using this\\n        model.\");\n                    }\n                    url = checkpoints_1.mobileNetCheckpoint(outputStride, multiplier, quantBytes);\n                    return [4 /*yield*/, tfconv.loadGraphModel(config.modelUrl || url)];\n                case 1:\n                    graphModel = _a.sent();\n                    mobilenet = new mobilenet_1.MobileNet(graphModel, outputStride);\n                    validInputResolution = util_1.getValidInputResolutionDimensions(config.inputResolution, mobilenet.outputStride);\n                    return [2 /*return*/, new PoseNet(mobilenet, validInputResolution)];\n            }\n        });\n    });\n}\nfunction loadResNet(config) {\n    return __awaiter(this, void 0, void 0, function () {\n        var outputStride, quantBytes, url, graphModel, resnet, validInputResolution;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    outputStride = config.outputStride;\n                    quantBytes = config.quantBytes;\n                    if (tf == null) {\n                        throw new Error(\"Cannot find TensorFlow.js. If you are using a <script> tag, please \" +\n                            \"also include @tensorflow/tfjs on the page before using this\\n        model.\");\n                    }\n                    url = checkpoints_1.resNet50Checkpoint(outputStride, quantBytes);\n                    return [4 /*yield*/, tfconv.loadGraphModel(config.modelUrl || url)];\n                case 1:\n                    graphModel = _a.sent();\n                    resnet = new resnet_1.ResNet(graphModel, outputStride);\n                    validInputResolution = util_1.getValidInputResolutionDimensions(config.inputResolution, resnet.outputStride);\n                    return [2 /*return*/, new PoseNet(resnet, validInputResolution)];\n            }\n        });\n    });\n}\n/**\n * Loads the PoseNet model instance from a checkpoint, with the ResNet\n * or MobileNet architecture. The model to be loaded is configurable using the\n * config dictionary ModelConfig. Please find more details in the\n * documentation of the ModelConfig.\n *\n * @param config ModelConfig dictionary that contains parameters for\n * the PoseNet loading process. Please find more details of each parameters\n * in the documentation of the ModelConfig interface. The predefined\n * `MOBILENET_V1_CONFIG` and `RESNET_CONFIG` can also be used as references\n * for defining your customized config.\n */\nfunction load(config) {\n    if (config === void 0) { config = MOBILENET_V1_CONFIG; }\n    return __awaiter(this, void 0, void 0, function () {\n        return __generator(this, function (_a) {\n            config = validateModelConfig(config);\n            if (config.architecture === 'ResNet50') {\n                return [2 /*return*/, loadResNet(config)];\n            }\n            else if (config.architecture === 'MobileNetV1') {\n                return [2 /*return*/, loadMobileNet(config)];\n            }\n            else {\n                return [2 /*return*/, null];\n            }\n            return [2 /*return*/];\n        });\n    });\n}\nexports.load = load;\n//# sourceMappingURL=posenet_model.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar MOBILENET_BASE_URL = 'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/';\nvar RESNET50_BASE_URL = 'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/resnet50/';\n// The PoseNet 2.0 ResNet50 models use the latest TensorFlow.js 1.0 model\n// format.\nfunction resNet50Checkpoint(stride, quantBytes) {\n    var graphJson = \"model-stride\" + stride + \".json\";\n    // quantBytes=4 corresponding to the non-quantized full-precision checkpoints.\n    if (quantBytes === 4) {\n        return RESNET50_BASE_URL + \"float/\" + graphJson;\n    }\n    else {\n        return RESNET50_BASE_URL + (\"quant\" + quantBytes + \"/\") + graphJson;\n    }\n}\nexports.resNet50Checkpoint = resNet50Checkpoint;\n// The PoseNet 2.0 MobileNetV1 models use the latest TensorFlow.js 1.0 model\n// format.\nfunction mobileNetCheckpoint(stride, multiplier, quantBytes) {\n    var toStr = { 1.0: '100', 0.75: '075', 0.50: '050' };\n    var graphJson = \"model-stride\" + stride + \".json\";\n    // quantBytes=4 corresponding to the non-quantized full-precision checkpoints.\n    if (quantBytes === 4) {\n        return MOBILENET_BASE_URL + (\"float/\" + toStr[multiplier] + \"/\") + graphJson;\n    }\n    else {\n        return MOBILENET_BASE_URL + (\"quant\" + quantBytes + \"/\" + toStr[multiplier] + \"/\") +\n            graphJson;\n    }\n}\nexports.mobileNetCheckpoint = mobileNetCheckpoint;\n//# sourceMappingURL=checkpoints.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar base_model_1 = require(\"./base_model\");\nvar imageNetMean = [-123.15, -115.90, -103.06];\nvar ResNet = /** @class */ (function (_super) {\n    __extends(ResNet, _super);\n    function ResNet() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    ResNet.prototype.preprocessInput = function (input) {\n        return tf.add(input, imageNetMean);\n    };\n    ResNet.prototype.nameOutputResults = function (results) {\n        var displacementFwd = results[0], displacementBwd = results[1], offsets = results[2], heatmap = results[3];\n        return { offsets: offsets, heatmap: heatmap, displacementFwd: displacementFwd, displacementBwd: displacementBwd };\n    };\n    return ResNet;\n}(base_model_1.BaseModel));\nexports.ResNet = ResNet;\n//# sourceMappingURL=resnet.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs-core\");\nvar keypoints_1 = require(\"./keypoints\");\nfunction eitherPointDoesntMeetConfidence(a, b, minConfidence) {\n    return (a < minConfidence || b < minConfidence);\n}\nfunction getAdjacentKeyPoints(keypoints, minConfidence) {\n    return keypoints_1.connectedPartIndices.reduce(function (result, _a) {\n        var leftJoint = _a[0], rightJoint = _a[1];\n        if (eitherPointDoesntMeetConfidence(keypoints[leftJoint].score, keypoints[rightJoint].score, minConfidence)) {\n            return result;\n        }\n        result.push([keypoints[leftJoint], keypoints[rightJoint]]);\n        return result;\n    }, []);\n}\nexports.getAdjacentKeyPoints = getAdjacentKeyPoints;\nvar NEGATIVE_INFINITY = Number.NEGATIVE_INFINITY, POSITIVE_INFINITY = Number.POSITIVE_INFINITY;\nfunction getBoundingBox(keypoints) {\n    return keypoints.reduce(function (_a, _b) {\n        var maxX = _a.maxX, maxY = _a.maxY, minX = _a.minX, minY = _a.minY;\n        var _c = _b.position, x = _c.x, y = _c.y;\n        return {\n            maxX: Math.max(maxX, x),\n            maxY: Math.max(maxY, y),\n            minX: Math.min(minX, x),\n            minY: Math.min(minY, y)\n        };\n    }, {\n        maxX: NEGATIVE_INFINITY,\n        maxY: NEGATIVE_INFINITY,\n        minX: POSITIVE_INFINITY,\n        minY: POSITIVE_INFINITY\n    });\n}\nexports.getBoundingBox = getBoundingBox;\nfunction getBoundingBoxPoints(keypoints) {\n    var _a = getBoundingBox(keypoints), minX = _a.minX, minY = _a.minY, maxX = _a.maxX, maxY = _a.maxY;\n    return [\n        { x: minX, y: minY }, { x: maxX, y: minY }, { x: maxX, y: maxY },\n        { x: minX, y: maxY }\n    ];\n}\nexports.getBoundingBoxPoints = getBoundingBoxPoints;\nfunction toTensorBuffers3D(tensors) {\n    return __awaiter(this, void 0, void 0, function () {\n        return __generator(this, function (_a) {\n            return [2 /*return*/, Promise.all(tensors.map(function (tensor) { return tensor.buffer(); }))];\n        });\n    });\n}\nexports.toTensorBuffers3D = toTensorBuffers3D;\nfunction scalePose(pose, scaleY, scaleX, offsetY, offsetX) {\n    if (offsetY === void 0) { offsetY = 0; }\n    if (offsetX === void 0) { offsetX = 0; }\n    return {\n        score: pose.score,\n        keypoints: pose.keypoints.map(function (_a) {\n            var score = _a.score, part = _a.part, position = _a.position;\n            return ({\n                score: score,\n                part: part,\n                position: {\n                    x: position.x * scaleX + offsetX,\n                    y: position.y * scaleY + offsetY\n                }\n            });\n        })\n    };\n}\nexports.scalePose = scalePose;\nfunction scalePoses(poses, scaleY, scaleX, offsetY, offsetX) {\n    if (offsetY === void 0) { offsetY = 0; }\n    if (offsetX === void 0) { offsetX = 0; }\n    if (scaleX === 1 && scaleY === 1 && offsetY === 0 && offsetX === 0) {\n        return poses;\n    }\n    return poses.map(function (pose) { return scalePose(pose, scaleY, scaleX, offsetY, offsetX); });\n}\nexports.scalePoses = scalePoses;\nfunction flipPoseHorizontal(pose, imageWidth) {\n    return {\n        score: pose.score,\n        keypoints: pose.keypoints.map(function (_a) {\n            var score = _a.score, part = _a.part, position = _a.position;\n            return ({\n                score: score,\n                part: part,\n                position: { x: imageWidth - 1 - position.x, y: position.y }\n            });\n        })\n    };\n}\nexports.flipPoseHorizontal = flipPoseHorizontal;\nfunction flipPosesHorizontal(poses, imageWidth) {\n    if (imageWidth <= 0) {\n        return poses;\n    }\n    return poses.map(function (pose) { return flipPoseHorizontal(pose, imageWidth); });\n}\nexports.flipPosesHorizontal = flipPosesHorizontal;\nfunction toValidInputResolution(inputResolution, outputStride) {\n    if (isValidInputResolution(inputResolution, outputStride)) {\n        return inputResolution;\n    }\n    return Math.floor(inputResolution / outputStride) * outputStride + 1;\n}\nexports.toValidInputResolution = toValidInputResolution;\nfunction validateInputResolution(inputResolution) {\n    tf.util.assert(typeof inputResolution === 'number' ||\n        typeof inputResolution === 'object', function () { return \"Invalid inputResolution \" + inputResolution + \". \" +\n        \"Should be a number or an object with width and height\"; });\n    if (typeof inputResolution === 'object') {\n        tf.util.assert(typeof inputResolution.width === 'number', function () { return \"inputResolution.width has a value of \" + inputResolution.width + \" which is invalid; it must be a number\"; });\n        tf.util.assert(typeof inputResolution.height === 'number', function () { return \"inputResolution.height has a value of \" + inputResolution.height + \" which is invalid; it must be a number\"; });\n    }\n}\nexports.validateInputResolution = validateInputResolution;\nfunction getValidInputResolutionDimensions(inputResolution, outputStride) {\n    validateInputResolution(inputResolution);\n    if (typeof inputResolution === 'object') {\n        return [\n            toValidInputResolution(inputResolution.height, outputStride),\n            toValidInputResolution(inputResolution.width, outputStride),\n        ];\n    }\n    else {\n        return [\n            toValidInputResolution(inputResolution, outputStride),\n            toValidInputResolution(inputResolution, outputStride),\n        ];\n    }\n}\nexports.getValidInputResolutionDimensions = getValidInputResolutionDimensions;\nvar VALID_OUTPUT_STRIDES = [8, 16, 32];\nfunction assertValidOutputStride(outputStride) {\n    tf.util.assert(typeof outputStride === 'number', function () { return 'outputStride is not a number'; });\n    tf.util.assert(VALID_OUTPUT_STRIDES.indexOf(outputStride) >= 0, function () { return \"outputStride of \" + outputStride + \" is invalid. \" +\n        \"It must be either 8, 16, or 32\"; });\n}\nexports.assertValidOutputStride = assertValidOutputStride;\nfunction isValidInputResolution(resolution, outputStride) {\n    return (resolution - 1) % outputStride === 0;\n}\nfunction assertValidResolution(resolution, outputStride) {\n    tf.util.assert(typeof resolution[0] === 'number' && typeof resolution[1] === 'number', function () { return \"both resolution values must be a number but had values \" + resolution; });\n    tf.util.assert(isValidInputResolution(resolution[0], outputStride), function () { return \"height of \" + resolution[0] + \" is invalid for output stride \" +\n        (outputStride + \".\"); });\n    tf.util.assert(isValidInputResolution(resolution[1], outputStride), function () { return \"width of \" + resolution[1] + \" is invalid for output stride \" +\n        (outputStride + \".\"); });\n}\nexports.assertValidResolution = assertValidResolution;\nfunction getInputTensorDimensions(input) {\n    return input instanceof tf.Tensor ? [input.shape[0], input.shape[1]] :\n        [input.height, input.width];\n}\nexports.getInputTensorDimensions = getInputTensorDimensions;\nfunction toInputTensor(input) {\n    return input instanceof tf.Tensor ? input : tf.browser.fromPixels(input);\n}\nexports.toInputTensor = toInputTensor;\nfunction toResizedInputTensor(input, resizeHeight, resizeWidth, flipHorizontal) {\n    return tf.tidy(function () {\n        var imageTensor = toInputTensor(input);\n        if (flipHorizontal) {\n            return tf.image.resizeBilinear(tf.reverse(imageTensor, 1), [resizeHeight, resizeWidth]);\n        }\n        else {\n            return tf.image.resizeBilinear(imageTensor, [resizeHeight, resizeWidth]);\n        }\n    });\n}\nexports.toResizedInputTensor = toResizedInputTensor;\nfunction padAndResizeTo(input, _a) {\n    var targetH = _a[0], targetW = _a[1];\n    var _b = getInputTensorDimensions(input), height = _b[0], width = _b[1];\n    var targetAspect = targetW / targetH;\n    var aspect = width / height;\n    var _c = [0, 0, 0, 0], padT = _c[0], padB = _c[1], padL = _c[2], padR = _c[3];\n    if (aspect < targetAspect) {\n        // pads the width\n        padT = 0;\n        padB = 0;\n        padL = Math.round(0.5 * (targetAspect * height - width));\n        padR = Math.round(0.5 * (targetAspect * height - width));\n    }\n    else {\n        // pads the height\n        padT = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n        padB = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n        padL = 0;\n        padR = 0;\n    }\n    var resized = tf.tidy(function () {\n        var imageTensor = toInputTensor(input);\n        imageTensor = tf.pad3d(imageTensor, [[padT, padB], [padL, padR], [0, 0]]);\n        return tf.image.resizeBilinear(imageTensor, [targetH, targetW]);\n    });\n    return { resized: resized, padding: { top: padT, left: padL, right: padR, bottom: padB } };\n}\nexports.padAndResizeTo = padAndResizeTo;\nfunction scaleAndFlipPoses(poses, _a, _b, padding, flipHorizontal) {\n    var height = _a[0], width = _a[1];\n    var inputResolutionHeight = _b[0], inputResolutionWidth = _b[1];\n    var scaleY = (height + padding.top + padding.bottom) / (inputResolutionHeight);\n    var scaleX = (width + padding.left + padding.right) / (inputResolutionWidth);\n    var scaledPoses = scalePoses(poses, scaleY, scaleX, -padding.top, -padding.left);\n    if (flipHorizontal) {\n        return flipPosesHorizontal(scaledPoses, width);\n    }\n    else {\n        return scaledPoses;\n    }\n}\nexports.scaleAndFlipPoses = scaleAndFlipPoses;\n//# sourceMappingURL=util.js.map","\n/** @license See the LICENSE file. */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// This code is auto-generated, do not modify this file!\nvar version = '2.2.2';\nexports.version = version;\n//# sourceMappingURL=version.js.map"]}